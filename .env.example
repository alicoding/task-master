# Task Master AI Configuration
# This file contains all configuration options for AI providers in Task Master

# ===== GLOBAL AI SETTINGS =====
# Set the AI provider type to use globally
# Options: openai, anthropic, custom-openai, mock
AI_PROVIDER_TYPE=mock

# Enable debug mode for AI operations (true/false)
AI_DEBUG=false

# ===== OPENAI CONFIGURATION =====
# API key for OpenAI
OPENAI_API_KEY=sk-your-openai-api-key-here

# Model to use with OpenAI
# Common options: gpt-4, gpt-4-turbo-preview, gpt-3.5-turbo
OPENAI_MODEL=gpt-4

# Temperature for OpenAI (0.0-1.0, higher = more creative)
OPENAI_TEMPERATURE=0.7

# Organization ID for OpenAI (only needed for organization accounts)
# OPENAI_ORGANIZATION=org-your-organization-id-here

# Base URL for OpenAI API (only change if using a proxy or non-standard endpoint)
# OPENAI_BASE_URL=https://api.openai.com

# ===== ANTHROPIC/CLAUDE CONFIGURATION =====
# API key for Anthropic
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Model to use with Anthropic
# Common options: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
ANTHROPIC_MODEL=claude-3-opus-20240229

# Temperature for Anthropic (0.0-1.0, higher = more creative)
ANTHROPIC_TEMPERATURE=0.7

# Base URL for Anthropic API (only change if using a proxy or non-standard endpoint)
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# ===== CUSTOM OPENAI-COMPATIBLE PROVIDER =====
# Custom OpenAI-compatible providers include Azure OpenAI, OpenRouter,
# local providers like Ollama, LM Studio, llama.cpp server, etc.

# API key for custom OpenAI provider (may be optional for local providers)
CUSTOM_OPENAI_API_KEY=your-custom-api-key-here

# Base URL for the custom OpenAI-compatible endpoint
# Examples:
# - Ollama: http://localhost:11434/v1
# - LM Studio: http://localhost:1234/v1
# - Azure OpenAI: https://your-resource-name.openai.azure.com/openai/deployments/your-deployment-name
CUSTOM_OPENAI_BASE_URL=http://localhost:11434/v1

# Model to use with custom OpenAI provider
# For local providers, this should match the model name in your provider
# For Azure, this is your deployment name
CUSTOM_OPENAI_MODEL=llama3

# Provider name for display purposes
CUSTOM_OPENAI_PROVIDER_NAME=Ollama

# Temperature for custom OpenAI provider (0.0-1.0)
CUSTOM_OPENAI_TEMPERATURE=0.7